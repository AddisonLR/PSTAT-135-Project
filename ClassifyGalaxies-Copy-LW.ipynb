{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the Galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necessary libraries\n",
    "import os\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import IPython.display as dp\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from sparkdl.image import imageIO\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from sparkdl import DeepImageFeaturizer\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"review_and_category_analytics\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "SUBMIT_ARGS = \"--packages databricks:spark-deep-learning:1.0.0-spark2.3-s_2.11 pyspark-shell\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = SUBMIT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Can Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small subset image directory\n",
    "direc = \"data/galaxy_images_classified/edge/\"\n",
    "\n",
    "fs = os.listdir(direc) #get list of image file names\n",
    "fs.sort() #sort by file name\n",
    "\n",
    "images = [] #create blank list which will store image objects\n",
    "\n",
    "for ea in fs: #for each image in the list of images\n",
    "    #add images object to the list of images\n",
    "    images.append(dp.Image(filename=direc + ea, format=\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show first 5 images\n",
    "for ea in range(5):\n",
    "    dp.display_png(images[ea])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT!!!! Change directory to full subset when not testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_df = ImageSchema.readImages(\"data/galaxy_images_classified/[TYPE]\")\n",
    "\n",
    "smooth_df = ImageSchema.readImages(\"data/galaxy_images_classified/smooth_small/\").withColumn(\"label\", lit(1))\n",
    "#edge_df = ImageSchema.readImages(\"data/galaxy_images_classified/edge/\").withColumn(\"label\", lit(2))\n",
    "#spiral_df = ImageSchema.readImages(\"data/galaxy_images_classified/spiral/\").withColumn(\"label\", lit(3))\n",
    "#other_df = ImageSchema.readImages(\"data/galaxy_images_classified/other/\").withColumn(\"label\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_df = ImageSchema.readImages(\"data/galaxy_images_classified/smooth_small/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_subset = smooth_df.limit(10)\n",
    "smooth_subset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_subset.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth_train, smooth_test = smooth_subset.randomSplit([0.1, 0.9], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train log regression\n",
    "featurizer = DeepImageFeaturizer(inputCol = \"image\",\n",
    "                                outputCol = \"features\",\n",
    "                                modelName = \"InceptionV3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build log regression transform\n",
    "lr = LogisticRegression(maxIter = 20, regParam = 0.05, \n",
    "                       elasticNetParam = 0.3, labelCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build pipeline\n",
    "p = Pipeline(stages = [featurizer, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build model\n",
    "p_model = p.fit(smooth_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.image import ImageSchema\n",
    "from sparkdl import TFImageTransformer\n",
    "import sparkdl.graph.utils as tfx  # strip_and_freeze_until was moved from sparkdl.transformers to sparkdl.graph.utils in 0.2.0\n",
    "from sparkdl.transformers import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "graph = tf.Graph()\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    image_arr = utils.imageInputPlaceholder()\n",
    "    resized_images = tf.image.resize_images(image_arr, (299, 299))\n",
    "    # the following step is not necessary for this graph, but can be for graphs with variables, etc\n",
    "    frozen_graph = tfx.strip_and_freeze_until([resized_images], graph, sess, return_graph=True)\n",
    "\n",
    "transformer = TFImageTransformer(inputCol=\"image\", outputCol=\"predictions\", graph=frozen_graph,\n",
    "                                 inputTensor=image_arr, outputTensor=resized_images,\n",
    "                                 outputMode=\"image\")\n",
    "\n",
    "image_df = ImageSchema.readImages(smooth_subset)\n",
    "processed_image_df = transformer.transform(smooth_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test datasets for each galaxy type\n",
    "smooth_train, smooth_test = smooth_df.randomSplit([0.1, 0.9], seed=123)\n",
    "edge_train, edge_test = edge_df.randomSplit([0.1, 0.9], seed=123)\n",
    "spiral_train, spiral_test = spiral_df.randomSplit([0.1, 0.9], seed=123)\n",
    "other_train, other_test = other_df.randomSplit([0.1, 0.9], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in other types of galaxies later!!!!!\n",
    "train_df = smooth_train.unionAll(other_train)\n",
    "test_df = smooth_test.unionAll(other_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.repartition(100)\n",
    "test_df = test_df.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName=\"InceptionV3\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.05, elasticNetParam=0.3, labelCol=\"label\")\n",
    "p = Pipeline(stages=[featurizer, lr])\n",
    "\n",
    "p_model = p.fit(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
