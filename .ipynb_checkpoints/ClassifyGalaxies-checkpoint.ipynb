{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify the Galaxies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import all necessary libraries\n",
    "import os\n",
    "\n",
    "from pyspark.sql.functions import lit\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "import IPython.display as dp\n",
    "from pyspark.ml.image import ImageSchema\n",
    "from sparkdl.image import imageIO\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from sparkdl import DeepImageFeaturizer\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"review_and_category_analytics\") \\\n",
    "    .config(\"spark.executor.memory\", '8g') \\\n",
    "    .config('spark.executor.cores', '4') \\\n",
    "    .config('spark.cores.max', '4') \\\n",
    "    .config(\"spark.driver.memory\",'8g') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sqlCtx = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame of Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Can Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small subset image directory\n",
    "direc = \"data/galaxy_images_classified/small_subset/\"\n",
    "\n",
    "fs = os.listdir(direc) #get list of image file names\n",
    "fs.sort() #sort by file name\n",
    "\n",
    "images = [] #create blank list which will store image objects\n",
    "\n",
    "for ea in fs: #for each image in the list of images\n",
    "    #add images object to the list of images\n",
    "    images.append(dp.Image(filename=direc + ea, format=\"png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Show first 5 images\n",
    "for ea in range(5):\n",
    "    dp.display_png(images[ea])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Image DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT!!!! Change directory to full subset when not testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_df = ImageSchema.readImages(\"data/galaxy_images_classified/[TYPE]\")\n",
    "\n",
    "smooth_df = ImageSchema.readImages(\"data/galaxy_images_classified/smooth/\").withColumn(\"label\", lit(1))\n",
    "edge_df = ImageSchema.readImages(\"data/galaxy_images_classified/edge/\").withColumn(\"label\", lit(2))\n",
    "spiral_df = ImageSchema.readImages(\"data/galaxy_images_classified/spiral/\").withColumn(\"label\", lit(3))\n",
    "other_df = ImageSchema.readImages(\"data/galaxy_images_classified/other/\").withColumn(\"label\", lit(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create train and test datasets for each galaxy type\n",
    "smooth_train, smooth_test = smooth_df.randomSplit([0.6, 0.4], seed=123)\n",
    "edge_train, edge_test = edge_df.randomSplit([0.6, 0.4], seed=123)\n",
    "spiral_train, spiral_test = spiral_df.randomSplit([0.6, 0.4], seed=123)\n",
    "other_train, other_test = other_df.randomSplit([0.6, 0.4], seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add in other types of galaxies later!!!!!\n",
    "train_df = smooth_train.unionAll(other_train)\n",
    "test_df = smooth_test.unionAll(other_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.repartition(100)\n",
    "test_df = test_df.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurizer = DeepImageFeaturizer(inputCol=\"image\", outputCol=\"features\", modelName=\"InceptionV3\")\n",
    "lr = LogisticRegression(maxIter=10, regParam=0.05, elasticNetParam=0.3, labelCol=\"label\")\n",
    "p = Pipeline(stages=[featurizer, lr])\n",
    "\n",
    "p_model = p.fit(train_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
